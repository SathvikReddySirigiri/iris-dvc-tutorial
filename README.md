# Iris DVC Tutorial

> **Machine Learning model versioning with DVC (Data Version Control)**

A hands-on tutorial demonstrating data and model versioning using DVC with the classic Iris dataset. Train two classification models (Logistic Regression and Random Forest) with different dataset sizes and track everything with Git and DVC.

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![DVC](https://img.shields.io/badge/DVC-3.30.0-orange.svg)](https://dvc.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3.0-green.svg)](https://scikit-learn.org/)

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Quick Start](#quick-start)
- [Usage](#usage)
- [Versions](#versions)
- [DVC Commands Reference](#dvc-commands-reference)
- [Collaboration](#collaboration)
- [What You'll Learn](#what-youll-learn)
- [Requirements](#requirements)
- [License](#license)

---

## ğŸ¯ Overview

This project demonstrates how to use **DVC (Data Version Control)** to version control:
- ğŸ“Š **Datasets** - Track different versions of your data
- ğŸ¤– **Models** - Version your trained models
- ğŸ“ˆ **Metrics** - Compare performance across versions
- ğŸ”„ **Experiments** - Easily switch between versions

We train two classifiers on the Iris dataset:
1. **Logistic Regression**
2. **Random Forest**

We create two versions:
- **v1.0**: Trained with 150 samples
- **v2.0**: Trained with 300 samples (augmented data)

---

## âœ¨ Features

- âœ… **Data versioning** with DVC
- âœ… **Model versioning** with DVC
- âœ… **Two ML algorithms** for comparison
- âœ… **Reproducible pipelines** with `dvc repro`
- âœ… **Remote storage** support (S3, GDrive, Azure)
- âœ… **Team collaboration** workflows
- âœ… **Metrics tracking** across versions
- âœ… **Complete documentation**

---

## ğŸ“ Project Structure

```
iris-dvc-tutorial/
â”œâ”€â”€ .dvc/                   # DVC configuration and cache
â”‚   â”œâ”€â”€ config              # Remote storage configuration
â”‚   â””â”€â”€ cache/              # Local cache (all versions stored here)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ iris.csv            # Current dataset (tracked by DVC)
â”‚   â””â”€â”€ iris.csv.dvc        # Dataset pointer (tracked by Git)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ logistic_regression.pkl     # LR model (tracked by DVC)
â”‚   â”œâ”€â”€ logistic_regression.pkl.dvc # Model pointer (tracked by Git)
â”‚   â”œâ”€â”€ random_forest.pkl           # RF model (tracked by DVC)
â”‚   â””â”€â”€ random_forest.pkl.dvc       # Model pointer (tracked by Git)
â”‚
â”œâ”€â”€ predictions/
â”‚   â”œâ”€â”€ lr_predictions.csv          # LR predictions (tracked by DVC)
â”‚   â”œâ”€â”€ lr_predictions.csv.dvc      # Pointer (tracked by Git)
â”‚   â”œâ”€â”€ rf_predictions.csv          # RF predictions (tracked by DVC)
â”‚   â””â”€â”€ rf_predictions.csv.dvc      # Pointer (tracked by Git)
â”‚
â”œâ”€â”€ train.py                # Training script
â”œâ”€â”€ prepare_data_v1.py      # Create 150-sample dataset
â”œâ”€â”€ prepare_data_v2.py      # Create 300-sample dataset
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ metrics.json            # Model performance metrics (tracked by Git)
â”œâ”€â”€ dvc.yaml               # DVC pipeline definition (optional)
â”œâ”€â”€ dvc.lock               # DVC pipeline lock file (optional)
â””â”€â”€ README.md              # This file
```

**Key Concept:**
- ğŸ”µ **Git tracks**: Code, `.dvc` files, small files like `metrics.json`
- ğŸŸ¢ **DVC tracks**: Large files like datasets, models, predictions

---

## ğŸš€
